{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b2d55c85-63fb-4099-95f6-cbe1814d7496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import time  # Add this line to import the time module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3e6f332a-975e-44a7-a975-046b7ccf6c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "72b2a05a-dd69-4e61-8347-e745f4959c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9ab7acf2-4dfe-4a89-a1c3-c939c40e9f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    0.534188\n",
       "1    0.465812\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check class distribution\n",
    "df['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c3e1789c-b3b9-452e-9b24-59df4f415037",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text'], df['label'], \n",
    "                                                                    random_state=2018, \n",
    "                                                                    test_size=0.3, \n",
    "                                                                    stratify=df['label'])\n",
    "\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
    "                                                                random_state=2018, \n",
    "                                                                test_size=0.5, \n",
    "                                                                stratify=temp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0bf30cf4-c9f1-4677-8904-8b8217b929da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained('jcblaise/bert-tagalog-base-cased')\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('jcblaise/bert-tagalog-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b69c859d-1c0f-4f0f-b9c3-4d11a9441d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f7d2bd42-a672-4478-a6b6-b1b945f19c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ronn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    max_length=max_seq_len,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")\n",
    "\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text.tolist(),\n",
    "    max_length=max_seq_len,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dfdc6b18-c8f7-4070-ac26-b4940fe5d000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensors for train and validation sets\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())\n",
    "\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0996c787-1053-4581-9f86-678d08f3225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d1e3d5b8-e540-469c-8489-f040fe01f063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "71f26356-2a57-4863-85b9-70ab0064eb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "    def __init__(self, bert):\n",
    "        super(BERT_Arch, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(768, 512)\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, sent_id, mask):\n",
    "        _, cls_hs = self.bert(sent_id, attention_mask=mask)\n",
    "        x = self.fc1(cls_hs)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "# Create the model and move it to the device\n",
    "model = BERT_Arch(bert).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbf7d32-7485-4e29-bdd1-7ef055337f57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5fade49b-e864-45ac-b648-76a0323be818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "52720c0f-09ad-48ea-b7c0-73da036aacdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "weights = torch.tensor(class_weights, dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7e3be602-d0ad-4252-aade-4a799a13e4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss(weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b6a97363-4f0a-4f97-b3b4-259f61532e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5111e862-8aa1-4dc9-9d65-55c4b98a9f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 10\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "linear(): argument 'input' (position 1) must be Tensor, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Epoch \u001b[39m\u001b[38;5;132;01m{:}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{:}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, epochs))\n\u001b[1;32m---> 36\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     valid_loss, _ \u001b[38;5;241m=\u001b[39m evaluate()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m valid_loss \u001b[38;5;241m<\u001b[39m best_valid_loss:\n",
      "Cell \u001b[1;32mIn[75], line 12\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(input_ids, attention_mask, labels)\u001b[0m\n\u001b[0;32m      9\u001b[0m sent_id, mask, labels \u001b[38;5;241m=\u001b[39m sent_id\u001b[38;5;241m.\u001b[39mto(device), mask\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Move labels to the same device\u001b[39;00m\n\u001b[0;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 12\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msent_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m cross_entropy(outputs, labels)\n\u001b[0;32m     14\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[68], line 13\u001b[0m, in \u001b[0;36mBERT_Arch.forward\u001b[1;34m(self, sent_id, mask)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, sent_id, mask):\n\u001b[0;32m     12\u001b[0m     _, cls_hs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert(sent_id, attention_mask\u001b[38;5;241m=\u001b[39mmask)\n\u001b[1;32m---> 13\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcls_hs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[0;32m     15\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not str"
     ]
    }
   ],
   "source": [
    "def train(input_ids, attention_mask, labels):\n",
    "    print(\"\\nTraining...\")\n",
    "    t0 = time.time()\n",
    "    total_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        sent_id, mask, labels = batch\n",
    "        sent_id, mask, labels = sent_id.to(device), mask.to(device), labels.to(device)  # Move labels to the same device\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(sent_id, mask)\n",
    "        loss = cross_entropy(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print progress every 50 batches\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print(f'  Batch {step} of {len(train_dataloader)}, Elapsed: {elapsed}')\n",
    "\n",
    "    # Calculate the average training loss\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    return avg_train_loss\n",
    "\n",
    "\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "\n",
    "    train_loss = train(train_seq, train_mask, train_y)\n",
    "    valid_loss, _ = evaluate()\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90950a8-27cd-4a44-93d4-53ed081f743a",
   "metadata": {},
   "outputs": [],
   "source": [
    " model.eval()\n",
    "    total_preds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2831a5d1-b94d-4a13-9053-48328c2eb2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch in val_dataloader:\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            preds = outputs.cpu().argmax(dim=1).numpy()\n",
    "            total_preds.extend(preds)\n",
    "\n",
    "    avg_val_loss = total_loss / len(val_dataloader)\n",
    "    print(f'Validation Loss: {avg_val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2741b80a-9d79-45ff-ba27-07e4cf45965a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb58715a-40fc-480b-b813-1582ecbfce1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
