{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f3b6514-9e4d-4c23-a450-c364a9c42ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "\n",
    "# specify GPU\n",
    "device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aca166-adb1-4988-8f2c-6c8b235d842c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c4b784b-0a99-4d20-a137-da451fb3082a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>#1 Sa aming oferta, makakatanggap ka ng 100% l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Mga kasamahan, ang iyong 777 ay maaari nang i-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Congratulations! Ikaw ay isa sa mga napiling 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Gusto mo bang kumita ng 100% pa? Huwag palampa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Eksklusibong alok para sa iyo: Libreng iPhone ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      1  #1 Sa aming oferta, makakatanggap ka ng 100% l...\n",
       "1      1  Mga kasamahan, ang iyong 777 ay maaari nang i-...\n",
       "2      1  Congratulations! Ikaw ay isa sa mga napiling 9...\n",
       "3      1  Gusto mo bang kumita ng 100% pa? Huwag palampa...\n",
       "4      1  Eksklusibong alok para sa iyo: Libreng iPhone ..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df05a42-1197-4ade-ba00-934283f1ee80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23758257-490b-4b39-8856-5f9d3cb2a18b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(468, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "59e76e17-0166-4a68-aad3-85a35a1d1dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    0.534188\n",
       "1    0.465812\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check class distribution\n",
    "df['label'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6101ae4c-3f77-4953-a43f-f4ad68a72f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d318956-bb8a-4eda-a865-26749ba78b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text'], df['label'], \n",
    "                                                                    random_state=2018, \n",
    "                                                                    test_size=0.3, \n",
    "                                                                    stratify=df['label'])\n",
    "\n",
    "# we will use temp_text and temp_labels to create validation and test set\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
    "                                                                random_state=2018, \n",
    "                                                                test_size=0.5, \n",
    "                                                                stratify=temp_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6312a183-cf5b-4b81-ad9e-c1137ab7e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained('jcblaise/bert-tagalog-base-cased')\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('jcblaise/bert-tagalog-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f266f549-36e7-4bbb-ba92-cba7b1db516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample data\n",
    "text = [\"this is a bert model tutorial\", \"we will fine-tune a bert model\"]\n",
    "\n",
    "# encode text\n",
    "sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c3fd33f1-dec9-45dc-adcf-235595527169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 1065, 565, 201, 30007, 5383, 11156, 10096, 13255, 10936, 120, 541, 102, 0], [101, 2962, 4399, 243, 14324, 229, 30031, 13255, 1869, 30007, 5383, 11156, 10096, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "print(sent_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1a7d2a0-aa55-4872-84db-5812dfcf57e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAApB0lEQVR4nO3dfXSU5Z3/8c8EJhMCTCJBSFISSF0lVAW3UWDE3RbMg5QqLDmi4m6RsrrbRlbIdqs5p0igdgG7K67dAHYPhvV4UjW7gkut0BAlriVBCHpWbE8WPZSoIWG1mwRIM5lfcv/+6C/zM+Rxnq7J5H6/zpkjc899X9f3O9c8fJzMg8OyLEsAAACGxEW7AAAAYC+EDwAAYBThAwAAGEX4AAAARhE+AACAUYQPAABgFOEDAAAYRfgAAABGjY92AVfq6elRU1OTJk+eLIfDEe1yAADACFiWpYsXLyo9PV1xcUO/tjHqwkdTU5MyMjKiXQYAAAjCxx9/rBkzZgy5z6gLH5MnT5b0h+LdbndUa/H5fPrlL3+p/Px8OZ3OqNZiGr3br3e79i3Rux17t2vfUuR6b29vV0ZGhv95fCijLnz0/qnF7XaPivCRmJgot9ttyxsnvdurd7v2LdG7HXu3a99S5HsfyVsmeMMpAAAwivABAACMInwAAACjCB8AAMAowgcAADAqoPAxa9YsORyOfqeioiJJUmdnp4qKipSSkqJJkyapsLBQLS0tESkcAADEpoDCx4kTJ3T+/Hn/qaqqSpJ09913S5I2btyogwcPqrKyUjU1NWpqatLKlSvDXzUAAIhZAX3Px9VXX93n/Pbt23XNNdfoa1/7mtra2rR3715VVFRoyZIlkqTy8nLNmTNHdXV1WrhwYfiqBgAAMSvoLxnr6urSCy+8oOLiYjkcDtXX18vn8yk3N9e/T3Z2tjIzM1VbWzto+PB6vfJ6vf7z7e3tkv7wJSg+ny/Y8sKid/5o1xEN9G6/3u3at0TvX/yvXdi1bylyvQcynsOyLCuYSV5++WWtXr1ajY2NSk9PV0VFhdauXdsnSEjS/PnztXjxYu3YsWPAcUpLS7Vly5Z+2ysqKpSYmBhMaQAAwLCOjg6tXr1abW1tw35DedCvfOzdu1dLly5Venp6sENIkkpKSlRcXOw/3/vd8Pn5+aPi69WrqqqUl5dny6/fpXd79W7XviV6t2Pvdu1bilzvvX+5GImgwse5c+d05MgRvfLKK/5tqamp6urqUmtrq5KTk/3bW1palJqaOuhYLpdLLper33an0zlqbhCjqRbT6N1+vdu1b4ne7di7XfuWwt97IGMF9T0f5eXlmjZtmpYtW+bflpOTI6fTqerqav+2hoYGNTY2yuPxBDMNAAAYgwJ+5aOnp0fl5eVas2aNxo///4cnJSVp3bp1Ki4u1pQpU+R2u7V+/Xp5PB4+6QIAAPwCDh9HjhxRY2Ojvv3tb/e7bOfOnYqLi1NhYaG8Xq8KCgq0a9eusBSK2DLrsdeCPva325cNvxMAIGYFHD7y8/M12AdkEhISVFZWprKyspALAwAAYxO/7QIAAIwifAAAAKMIHwAAwCjCBwAAMIrwAQAAjCJ8AAAAowgfAADAKMIHAAAwivABAACMInwAAACjCB8AAMAowgcAADCK8AEAAIwifAAAAKMIHwAAwCjCBwAAMIrwAQAAjCJ8AAAAowgfAADAKMIHAAAwivABAACMInwAAACjCB8AAMAowgcAADCK8AEAAIwifAAAAKMIHwAAwCjCBwAAMIrwAQAAjCJ8AAAAowgfAADAKMIHAAAwivABAACMInwAAACjCB8AAMAowgcAADCK8AEAAIwifAAAAKMIHwAAwCjCBwAAMCrg8PHpp5/qz//8z5WSkqIJEyboxhtv1MmTJ/2XW5alxx9/XGlpaZowYYJyc3N15syZsBYNAABiV0Dh43//93+1aNEiOZ1Ovf766/r1r3+tf/zHf9RVV13l3+fJJ5/UM888oz179uj48eOaOHGiCgoK1NnZGfbiAQBA7BkfyM47duxQRkaGysvL/duysrL8/7YsS08//bR+8IMfaPny5ZKk559/XtOnT9eBAwd07733hqlsAAAQqwIKH//xH/+hgoIC3X333aqpqdGXvvQlffe739WDDz4oSTp79qyam5uVm5vrPyYpKUkLFixQbW3tgOHD6/XK6/X6z7e3t0uSfD6ffD5fUE2FS+/80a4jGkLt3TXOCnnuaLHrutu1b4nev/hfu7Br31Lkeg9kPIdlWSN+lkhISJAkFRcX6+6779aJEyf0yCOPaM+ePVqzZo2OHTumRYsWqampSWlpaf7jVq1aJYfDoZdeeqnfmKWlpdqyZUu/7RUVFUpMTBxxIwAAIHo6Ojq0evVqtbW1ye12D7lvQOEjPj5eN998s44dO+bf9jd/8zc6ceKEamtrgwofA73ykZGRoc8++2zY4iPN5/OpqqpKeXl5cjqdUa3FtFB7v6H0cNBzny4tCPrYcLDrutu1b4ne7di7XfuWItd7e3u7pk6dOqLwEdCfXdLS0vSVr3ylz7Y5c+bo3//93yVJqampkqSWlpY+4aOlpUU33XTTgGO6XC65XK5+251O56i5QYymWkwLtndvtyOkOUcDu667XfuW6N2Ovdu1byn8vQcyVkCfdlm0aJEaGhr6bPvv//5vzZw5U9If3nyampqq6upq/+Xt7e06fvy4PB5PIFMBAIAxKqBXPjZu3Khbb71Vf//3f69Vq1bpnXfe0U9/+lP99Kc/lSQ5HA5t2LBBTzzxhK699lplZWVp06ZNSk9P14oVKyJRPwAAiDEBhY9bbrlF+/fvV0lJibZu3aqsrCw9/fTTuv/++/37fP/739fly5f10EMPqbW1VbfddpsOHTrkf7MqAACwt4DChyR985vf1De/+c1BL3c4HNq6dau2bt0aUmEAAGBs4rddAACAUYQPAABgFOEDAAAYRfgAAABGET4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYBThAwAAGEX4AAAARhE+AACAUYQPAABgFOEDAAAYRfgAAABGET4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYBThAwAAGEX4AAAARhE+AACAUYQPAABgFOEDAAAYRfgAAABGET4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYBThAwAAGEX4AAAARhE+AACAUYQPAABgFOEDAAAYRfgAAABGBRQ+SktL5XA4+pyys7P9l3d2dqqoqEgpKSmaNGmSCgsL1dLSEvaiAQBA7Ar4lY/rr79e58+f95/efvtt/2UbN27UwYMHVVlZqZqaGjU1NWnlypVhLRgAAMS28QEfMH68UlNT+21va2vT3r17VVFRoSVLlkiSysvLNWfOHNXV1WnhwoWhVwsAAGJewOHjzJkzSk9PV0JCgjwej7Zt26bMzEzV19fL5/MpNzfXv292drYyMzNVW1s7aPjwer3yer3+8+3t7ZIkn88nn88XaHlh1Tt/tOuIhlB7d42zQp47Wuy67nbtW6L3L/7XLuzatxS53gMZz2FZ1oifJV5//XVdunRJs2fP1vnz57VlyxZ9+umnOn36tA4ePKi1a9f2CRKSNH/+fC1evFg7duwYcMzS0lJt2bKl3/aKigolJiaOuBEAABA9HR0dWr16tdra2uR2u4fcN6DwcaXW1lbNnDlTTz31lCZMmBBU+BjolY+MjAx99tlnwxYfaT6fT1VVVcrLy5PT6YxqLaaF2vsNpYeDnvt0aUHQx4aDXdc9FvqO1O0qFnqPFLv2bte+pcj13t7erqlTp44ofAT8Z5cvSk5O1nXXXacPP/xQeXl56urqUmtrq5KTk/37tLS0DPgekV4ul0sul6vfdqfTOWpuEKOpFtOC7d3b7QhpztHArus+mvuO9O1qNPceaXbt3a59S+HvPZCxQvqej0uXLumjjz5SWlqacnJy5HQ6VV1d7b+8oaFBjY2N8ng8oUwDAADGkIBe+fje976nO++8UzNnzlRTU5M2b96scePG6b777lNSUpLWrVun4uJiTZkyRW63W+vXr5fH4+GTLgAAwC+g8PHJJ5/ovvvu0+eff66rr75at912m+rq6nT11VdLknbu3Km4uDgVFhbK6/WqoKBAu3btikjhAAAgNgUUPl588cUhL09ISFBZWZnKyspCKgoAAIxd/LYLAAAwivABAACMInwAAACjCB8AAMAowgcAADCK8AEAAIwifAAAAKMIHwAAwCjCBwAAMIrwAQAAjCJ8AAAAowgfAADAKMIHAAAwivABAACMInwAAACjCB8AAMAowgcAADCK8AEAAIwifAAAAKMIHwAAwCjCBwAAMIrwAQAAjCJ8AAAAowgfAADAKMIHAAAwivABAACMInwAAACjCB8AAMAowgcAADCK8AEAAIwifAAAAKMIHwAAwCjCBwAAMIrwAQAAjBof7QIwut1Qeljebke0y8AYMuux16JdAoAo45UPAABgFOEDAAAYRfgAAABGET4AAIBRhA8AAGBUSOFj+/btcjgc2rBhg39bZ2enioqKlJKSokmTJqmwsFAtLS2h1gkAAMaIoMPHiRMn9Oyzz2ru3Ll9tm/cuFEHDx5UZWWlampq1NTUpJUrV4ZcKAAAGBuCCh+XLl3S/fffr3/5l3/RVVdd5d/e1tamvXv36qmnntKSJUuUk5Oj8vJyHTt2THV1dWErGgAAxK6gvmSsqKhIy5YtU25urp544gn/9vr6evl8PuXm5vq3ZWdnKzMzU7W1tVq4cGG/sbxer7xer/98e3u7JMnn88nn8wVTXtj0zh/tOqKht2dXnBW1uaPFrutuqm/XOPO3KWnovuy65pJ9e7dr31Lkeg9kvIDDx4svvqhTp07pxIkT/S5rbm5WfHy8kpOT+2yfPn26mpubBxxv27Zt2rJlS7/tv/zlL5WYmBhoeRFRVVUV7RKi5oc39xif8xe/+IXxOQdi13WPdN9Pzo/o8IMaye3Krmsu2bd3u/Ythb/3jo6OEe8bUPj4+OOP9cgjj6iqqkoJCQkBFzaQkpISFRcX+8+3t7crIyND+fn5crvdYZkjWD6fT1VVVcrLy5PT6YxqLab19r7pZJy8PWa/Xv10aYHR+a5k13U31fcNpYcjNvZQhrpd2XXNJfv2bte+pcj13vuXi5EIKHzU19frwoUL+upXv+rf1t3drbfeekv//M//rMOHD6urq0utra19Xv1oaWlRamrqgGO6XC65XK5+251O56i5QYymWkzz9jiM/7bLaLmu7bruke47Wr8VNJKe7Lrmkn17t2vfUvh7D2SsgMLH7bffrvfff7/PtrVr1yo7O1uPPvqoMjIy5HQ6VV1drcLCQklSQ0ODGhsb5fF4ApkKAACMUQGFj8mTJ+uGG27os23ixIlKSUnxb1+3bp2Ki4s1ZcoUud1urV+/Xh6PZ8A3mwIAAPsJ6tMuQ9m5c6fi4uJUWFgor9ergoIC7dq1K9zTAACAGBVy+Dh69Gif8wkJCSorK1NZWVmoQwMAgDGI33YBAABGET4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYBThAwAAGEX4AAAARhE+AACAUYQPAABgFOEDAAAYRfgAAABGET4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYBThAwAAGEX4AAAARhE+AACAUYQPAABgFOEDAAAYRfgAAABGET4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYBThAwAAGEX4AAAARhE+AACAUYQPAABgFOEDAAAYRfgAAABGET4AAIBRhA8AAGAU4QMAABgVUPjYvXu35s6dK7fbLbfbLY/Ho9dff91/eWdnp4qKipSSkqJJkyapsLBQLS0tYS8aAADEroDCx4wZM7R9+3bV19fr5MmTWrJkiZYvX64PPvhAkrRx40YdPHhQlZWVqqmpUVNTk1auXBmRwgEAQGwaH8jOd955Z5/zP/rRj7R7927V1dVpxowZ2rt3ryoqKrRkyRJJUnl5uebMmaO6ujotXLgwfFUDAICYFVD4+KLu7m5VVlbq8uXL8ng8qq+vl8/nU25urn+f7OxsZWZmqra2dtDw4fV65fV6/efb29slST6fTz6fL9jywqJ3/mjXEQ29PbvirKjNHS12XXdTfbvGmb9NSUP3Zdc1l+zbu137liLXeyDjOSzLCuiR4P3335fH41FnZ6cmTZqkiooKfeMb31BFRYXWrl3bJ0hI0vz587V48WLt2LFjwPFKS0u1ZcuWftsrKiqUmJgYSGkAACBKOjo6tHr1arW1tcntdg+5b8CvfMyePVvvvfee2tra9G//9m9as2aNampqgi62pKRExcXF/vPt7e3KyMhQfn7+sMVHms/nU1VVlfLy8uR0OqNai2m9vW86GSdvj8Po3KdLC4I+9obSwyHPa9d1N9V3KGsUiqFuV3Zdc8m+vdu1bylyvff+5WIkAg4f8fHx+qM/+iNJUk5Ojk6cOKF/+qd/0j333KOuri61trYqOTnZv39LS4tSU1MHHc/lcsnlcvXb7nQ6R80NYjTVYpq3xyFvt9nwEcp1HUqtV85r13WPdN+mb0+9RtKTXddcsm/vdu1bCn/vgYwV8vd89PT0yOv1KicnR06nU9XV1f7LGhoa1NjYKI/HE+o0AABgjAjolY+SkhItXbpUmZmZunjxoioqKnT06FEdPnxYSUlJWrdunYqLizVlyhS53W6tX79eHo+HT7oAAAC/gMLHhQsX9K1vfUvnz59XUlKS5s6dq8OHDysvL0+StHPnTsXFxamwsFBer1cFBQXatWtXRAoHAACxKaDwsXfv3iEvT0hIUFlZmcrKykIqCgAAjF38tgsAADCK8AEAAIwifAAAAKMIHwAAwCjCBwAAMIrwAQAAjCJ8AAAAowgfAADAKMIHAAAwivABAACMInwAAACjCB8AAMAowgcAADCK8AEAAIwifAAAAKMIHwAAwCjCBwAAMIrwAQAAjCJ8AAAAowgfAADAKMIHAAAwivABAACMInwAAACjCB8AAMCo8dEuABgLZj32WtDH/nb7sjBWAgCjH698AAAAowgfAADAKMIHAAAwivABAACMInwAAACjCB8AAMAowgcAADCK8AEAAIwifAAAAKMIHwAAwCjCBwAAMIrwAQAAjCJ8AAAAowgfAADAKMIHAAAwKqDwsW3bNt1yyy2aPHmypk2bphUrVqihoaHPPp2dnSoqKlJKSoomTZqkwsJCtbS0hLVoAAAQuwIKHzU1NSoqKlJdXZ2qqqrk8/mUn5+vy5cv+/fZuHGjDh48qMrKStXU1KipqUkrV64Me+EAACA2jQ9k50OHDvU5v2/fPk2bNk319fX60z/9U7W1tWnv3r2qqKjQkiVLJEnl5eWaM2eO6urqtHDhwvBVDgAAYlJA4eNKbW1tkqQpU6ZIkurr6+Xz+ZSbm+vfJzs7W5mZmaqtrR0wfHi9Xnm9Xv/59vZ2SZLP55PP5wulvJD1zh/tOqKht2dXnBW1uYPhGhd8vVeudyB1hGPeaDN1ew/lugrFUH1xX7df73btW4pc74GM57AsK6hHgp6eHt11111qbW3V22+/LUmqqKjQ2rVr+4QJSZo/f74WL16sHTt29BuntLRUW7Zs6be9oqJCiYmJwZQGAAAM6+jo0OrVq9XW1ia32z3kvkG/8lFUVKTTp0/7g0ewSkpKVFxc7D/f3t6ujIwM5efnD1t8pPl8PlVVVSkvL09OpzOqtZjW2/umk3Hy9jiMzn26tCDoY28oPRzyvMGsezjmNe3Kml1xln54c8+I1jxaaxSKoWrmvm6/3u3atxS53nv/cjESQYWPhx9+WD//+c/11ltvacaMGf7tqamp6urqUmtrq5KTk/3bW1palJqaOuBYLpdLLper33an0zlqbhCjqRbTvD0OebvNho9QrutQar1y3kDWPZzzmjJYzSNZ82itUShGUrOd7+t27d2ufUvh7z2QsQL6tItlWXr44Ye1f/9+vfHGG8rKyupzeU5OjpxOp6qrq/3bGhoa1NjYKI/HE8hUAABgjArolY+ioiJVVFTo1Vdf1eTJk9Xc3CxJSkpK0oQJE5SUlKR169apuLhYU6ZMkdvt1vr16+XxePikCwAAkBRg+Ni9e7ck6etf/3qf7eXl5XrggQckSTt37lRcXJwKCwvl9XpVUFCgXbt2haVYAAAQ+wIKHyP5YExCQoLKyspUVlYWdFEAAGDs4rddAACAUYQPAABgFOEDAAAYRfgAAABGET4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYBThAwAAGEX4AAAARhE+AACAUYQPAABgFOEDAAAYRfgAAABGET4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYBThAwAAGEX4AAAARhE+AACAUYQPAABgFOEDAAAYRfgAAABGET4AAIBR46NdAIY367HXgj72t9uXhbESAABCxysfAADAKMIHAAAwivABAACMInwAAACjeMMpEGW8oXj0Y42A8OKVDwAAYBThAwAAGEX4AAAARhE+AACAUYQPAABgVMDh46233tKdd96p9PR0ORwOHThwoM/llmXp8ccfV1pamiZMmKDc3FydOXMmXPUCAIAYF3D4uHz5subNm6eysrIBL3/yySf1zDPPaM+ePTp+/LgmTpyogoICdXZ2hlwsAACIfQF/z8fSpUu1dOnSAS+zLEtPP/20fvCDH2j58uWSpOeff17Tp0/XgQMHdO+994ZWLQAAiHlh/ZKxs2fPqrm5Wbm5uf5tSUlJWrBggWprawcMH16vV16v13++vb1dkuTz+eTz+cJZXsB65492Ha5xVtDHBlt773GuuODnDlYo13c4rqtg1j2UeUMRzuuqd61HsubRWqNQDFXzcGsejfugKaPlcc40u/YtRa73QMZzWJYV9L3K4XBo//79WrFihSTp2LFjWrRokZqampSWlubfb9WqVXI4HHrppZf6jVFaWqotW7b0215RUaHExMRgSwMAAAZ1dHRo9erVamtrk9vtHnLfqH+9eklJiYqLi/3n29vblZGRofz8/GGLjzSfz6eqqirl5eXJ6XRGrY4bSg8Hfezp0oKgjuvtfdPJOHl7HEHPH4xga5bCc10Fs+6hzBuKcF5XrjhLP7y5Z0RrHq01CsVQNQ+35tG4D5oyWh7nTLNr31Lkeu/9y8VIhDV8pKamSpJaWlr6vPLR0tKim266acBjXC6XXC5Xv+1Op3PU3CCiXYu3O/gn/1Dr9vY4Qpo/GKHUHM7rKpB1N30d9YrEdTWSNY/WGoViJDUPtubRvA+aEu3HuWixa99S+HsPZKywfs9HVlaWUlNTVV1d7d/W3t6u48ePy+PxhHMqAAAQowJ+5ePSpUv68MMP/efPnj2r9957T1OmTFFmZqY2bNigJ554Qtdee62ysrK0adMmpaen+98XAgAA7C3g8HHy5EktXrzYf773/Rpr1qzRvn379P3vf1+XL1/WQw89pNbWVt122206dOiQEhISwlc1AACIWQGHj69//esa6gMyDodDW7du1datW0MqDAAAjE38tgsAADCK8AEAAIwifAAAAKMIHwAAwCjCBwAAMIrwAQAAjCJ8AAAAowgfAADAKMIHAAAwivABAACMInwAAACjCB8AAMAowgcAADCK8AEAAIwifAAAAKMIHwAAwCjCBwAAMIrwAQAAjCJ8AAAAo8ZHuwAAwMBmPfZaSMf/dvuyMFUChBevfAAAAKMIHwAAwCjCBwAAMIrwAQAAjCJ8AAAAowgfAADAKMIHAAAwivABAACMInwAAACjCB8AAMAowgcAADCK8AEAAIwifAAAAKMIHwAAwKjx0S4AABAZsx57bdh9XOMsPTlfuqH0sLzdDv/2325fFtF5BxPKvIgdvPIBAACMInwAAACjCB8AAMAowgcAADDKdm84DeSNUIO9ESsYvIkKACIrlMf3WHyMDvaNvb29R1PEXvkoKyvTrFmzlJCQoAULFuidd96J1FQAACCGRCR8vPTSSyouLtbmzZt16tQpzZs3TwUFBbpw4UIkpgMAADEkIuHjqaee0oMPPqi1a9fqK1/5ivbs2aPExEQ999xzkZgOAADEkLC/56Orq0v19fUqKSnxb4uLi1Nubq5qa2v77e/1euX1ev3n29raJEm/+93v5PP5wl2exv+fyyPft8dSR0ePxvvi1N0T2ns+Pv/886CPDaTmcM3r8/nU0dERlt4DFe3rqrf3zz//XE6nM+LzhiKc11Ugt/dorVEohqp5uDWPxn0w1HlHPMcg6x7t+2Gk572y71DmjZZgr+fe3gN5jBuJixcvSpIsyxp+ZyvMPv30U0uSdezYsT7b/+7v/s6aP39+v/03b95sSeLEiRMnTpw4jYHTxx9/PGxWiPqnXUpKSlRcXOw/39PTo9/97ndKSUmRw2H2/7iv1N7eroyMDH388cdyu91RrcU0erdf73btW6J3O/Zu176lyPVuWZYuXryo9PT0YfcNe/iYOnWqxo0bp5aWlj7bW1palJqa2m9/l8sll8vVZ1tycnK4ywqJ2+223Y2zF73br3e79i3Rux17t2vfUmR6T0pKGtF+YX/DaXx8vHJyclRdXe3f1tPTo+rqank8nnBPBwAAYkxE/uxSXFysNWvW6Oabb9b8+fP19NNP6/Lly1q7dm0kpgMAADEkIuHjnnvu0f/8z//o8ccfV3Nzs2666SYdOnRI06dPj8R0EeNyubR58+Z+fxayA3q3X+927Vuidzv2bte+pdHRu8OyRvKZGAAAgPDgh+UAAIBRhA8AAGAU4QMAABhF+AAAAEbZNnxs27ZNt9xyiyZPnqxp06ZpxYoVamhoGPKYffv2yeFw9DklJCQYqjh8SktL+/WRnZ095DGVlZXKzs5WQkKCbrzxRv3iF78wVG14zZo1q1/vDodDRUVFA+4fq2v+1ltv6c4771R6erocDocOHDjQ53LLsvT4448rLS1NEyZMUG5urs6cOTPsuGVlZZo1a5YSEhK0YMECvfPOOxHqIHhD9e7z+fToo4/qxhtv1MSJE5Wenq5vfetbampqGnLMYO4z0TDcuj/wwAP9+rjjjjuGHXe0r/twfQ90n3c4HPrxj3886JixsOYjeR7r7OxUUVGRUlJSNGnSJBUWFvb7EtArBfv4EAjbho+amhoVFRWprq5OVVVV8vl8ys/P1+XLQ/9Qj9vt1vnz5/2nc+fOGao4vK6//vo+fbz99tuD7nvs2DHdd999Wrdund59912tWLFCK1as0OnTpw1WHB4nTpzo03dVVZUk6e677x70mFhc88uXL2vevHkqKysb8PInn3xSzzzzjPbs2aPjx49r4sSJKigoUGdn56BjvvTSSyouLtbmzZt16tQpzZs3TwUFBbpw4UKk2gjKUL13dHTo1KlT2rRpk06dOqVXXnlFDQ0Nuuuuu4YdN5D7TLQMt+6SdMcdd/Tp42c/+9mQY8bCug/X9xf7PX/+vJ577jk5HA4VFhYOOe5oX/ORPI9t3LhRBw8eVGVlpWpqatTU1KSVK1cOOW4wjw8BC8ePyY0FFy5csCRZNTU1g+5TXl5uJSUlmSsqQjZv3mzNmzdvxPuvWrXKWrZsWZ9tCxYssP7qr/4qzJWZ98gjj1jXXHON1dPTM+DlY2HNJVn79+/3n+/p6bFSU1OtH//4x/5tra2tlsvlsn72s58NOs78+fOtoqIi//nu7m4rPT3d2rZtW0TqDocrex/IO++8Y0myzp07N+g+gd5nRoOBel+zZo21fPnygMaJtXUfyZovX77cWrJkyZD7xOKaX/k81traajmdTquystK/z29+8xtLklVbWzvgGME+PgTKtq98XKmtrU2SNGXKlCH3u3TpkmbOnKmMjAwtX75cH3zwgYnywu7MmTNKT0/Xl7/8Zd1///1qbGwcdN/a2lrl5ub22VZQUKDa2tpIlxlRXV1deuGFF/Ttb397yB8xHCtr3uvs2bNqbm7us6ZJSUlasGDBoGva1dWl+vr6PsfExcUpNzc35m8HbW1tcjgcw/6mVCD3mdHs6NGjmjZtmmbPnq3vfOc7Q/6U/Fhc95aWFr322mtat27dsPvG2ppf+TxWX18vn8/XZ/2ys7OVmZk56PoF8/gQDMKH/vDbMxs2bNCiRYt0ww03DLrf7Nmz9dxzz+nVV1/VCy+8oJ6eHt1666365JNPDFYbugULFmjfvn06dOiQdu/erbNnz+pP/uRPdPHixQH3b25u7vfttNOnT1dzc7OJciPmwIEDam1t1QMPPDDoPmNlzb+od90CWdPPPvtM3d3dY+520NnZqUcffVT33XffkD+wFeh9ZrS644479Pzzz6u6ulo7duxQTU2Nli5dqu7u7gH3H4vr/q//+q+aPHnysH96iLU1H+h5rLm5WfHx8f2C9VDrF8zjQzAi8vXqsaaoqEinT58e9u95Ho+nz4/j3XrrrZozZ46effZZ/fCHP4x0mWGzdOlS/7/nzp2rBQsWaObMmXr55ZdH9H8DY8XevXu1dOnSIX/+eaysOfrz+XxatWqVLMvS7t27h9x3rNxn7r33Xv+/b7zxRs2dO1fXXHONjh49qttvvz2KlZnz3HPP6f777x/2jeOxtuYjfR4bLWz/ysfDDz+sn//853rzzTc1Y8aMgI51Op364z/+Y3344YcRqs6M5ORkXXfddYP2kZqa2u/d0S0tLUpNTTVRXkScO3dOR44c0V/+5V8GdNxYWPPedQtkTadOnapx48aNmdtBb/A4d+6cqqqqAv5Z8eHuM7Hiy1/+sqZOnTpoH2Nt3f/zP/9TDQ0NAd/vpdG95oM9j6Wmpqqrq0utra199h9q/YJ5fAiGbcOHZVl6+OGHtX//fr3xxhvKysoKeIzu7m69//77SktLi0CF5ly6dEkfffTRoH14PB5VV1f32VZVVdXnFYFYU15ermnTpmnZsmUBHTcW1jwrK0upqal91rS9vV3Hjx8fdE3j4+OVk5PT55ienh5VV1fH3O2gN3icOXNGR44cUUpKSsBjDHefiRWffPKJPv/880H7GEvrLv3h1c6cnBzNmzcv4GNH45oP9zyWk5Mjp9PZZ/0aGhrU2Ng46PoF8/gQbPG29J3vfMdKSkqyjh49ap0/f95/6ujo8O/zF3/xF9Zjjz3mP79lyxbr8OHD1kcffWTV19db9957r5WQkGB98MEH0WghaH/7t39rHT161Dp79qz1q1/9ysrNzbWmTp1qXbhwwbKs/n3/6le/ssaPH2/9wz/8g/Wb3/zG2rx5s+V0Oq33338/Wi2EpLu728rMzLQeffTRfpeNlTW/ePGi9e6771rvvvuuJcl66qmnrHfffdf/iY7t27dbycnJ1quvvmr913/9l7V8+XIrKyvL+v3vf+8fY8mSJdZPfvIT//kXX3zRcrlc1r59+6xf//rX1kMPPWQlJydbzc3NxvsbylC9d3V1WXfddZc1Y8YM67333utz3/d6vf4xrux9uPvMaDFU7xcvXrS+973vWbW1tdbZs2etI0eOWF/96leta6+91urs7PSPEYvrPtzt3bIsq62tzUpMTLR279494BixuOYjeR7767/+ayszM9N64403rJMnT1oej8fyeDx9xpk9e7b1yiuv+M+P5PEhVLYNH5IGPJWXl/v3+drXvmatWbPGf37Dhg1WZmamFR8fb02fPt36xje+YZ06dcp88SG65557rLS0NCs+Pt760pe+ZN1zzz3Whx9+6L/8yr4ty7Jefvll67rrrrPi4+Ot66+/3nrttdcMVx0+hw8ftiRZDQ0N/S4bK2v+5ptvDnj77u2tp6fH2rRpkzV9+nTL5XJZt99+e7/rY+bMmdbmzZv7bPvJT37ivz7mz59v1dXVGepo5Ibq/ezZs4Pe9998803/GFf2Ptx9ZrQYqveOjg4rPz/fuvrqqy2n02nNnDnTevDBB/uFiFhc9+Fu75ZlWc8++6w1YcIEq7W1dcAxYnHNR/I89vvf/9767ne/a1111VVWYmKi9Wd/9mfW+fPn+43zxWNG8vgQKsf/mxgAAMAI277nAwAARAfhAwAAGEX4AAAARhE+AACAUYQPAABgFOEDAAAYRfgAAABGET4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFH/F+i2iMJZKnd7AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_len = [len(i.split()) for i in train_text]\n",
    "\n",
    "pd.Series(seq_len).hist(bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7dad572e-db3a-4eb5-9b28-60c7d859737c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3593b06e-5562-41e0-bf8f-8fef4c8df843",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ronn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# tokenize and encode sequences in the training set\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    max_length=max_seq_len,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text.tolist(),\n",
    "    max_length = max_seq_len,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the test set\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_text.tolist(),\n",
    "    max_length = max_seq_len,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f67def-abdb-42e4-b09f-fceb090e538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(input_ids, attention_mask, labels, batch_size, is_train=True):\n",
    "    data = TensorDataset(input_ids, attention_mask, labels)\n",
    "    sampler = RandomSampler(data) if is_train else SequentialSampler(data)\n",
    "    return DataLoader(data, sampler=sampler, batch_size=batch_size)\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e5a45498-976e-4f01-9f1b-0a19e355a0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train set\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())\n",
    "\n",
    "# for validation set\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_labels.tolist())\n",
    "\n",
    "# for test set\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(test_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2f9a1c30-fc1a-42b9-bb3a-179af1dfb428",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "#define a batch size\n",
    "batch_size = 32\n",
    "\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b948cb2-b7a3-45a6-af24-9f9887d5340b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1e27794a-40ae-4913-94c5-950b6a937a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, bert):\n",
    "      \n",
    "      super(BERT_Arch, self).__init__()\n",
    "\n",
    "      self.bert = bert \n",
    "      \n",
    "      # dropout layer\n",
    "      self.dropout = nn.Dropout(0.1)\n",
    "      \n",
    "      # relu activation function\n",
    "      self.relu =  nn.ReLU()\n",
    "\n",
    "      # dense layer 1\n",
    "      self.fc1 = nn.Linear(768,512)\n",
    "      \n",
    "      # dense layer 2 (Output layer)\n",
    "      self.fc2 = nn.Linear(512,2)\n",
    "\n",
    "      #softmax activation function\n",
    "      self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    #define the forward pass\n",
    "    def forward(self, sent_id, mask):\n",
    "\n",
    "      #pass the inputs to the model  \n",
    "      _, cls_hs = self.bert(sent_id, attention_mask=mask)\n",
    "      \n",
    "      x = self.fc1(cls_hs)\n",
    "\n",
    "      x = self.relu(x)\n",
    "\n",
    "      x = self.dropout(x)\n",
    "\n",
    "      # output layer\n",
    "      x = self.fc2(x)\n",
    "      \n",
    "      # apply softmax activation\n",
    "      x = self.softmax(x)\n",
    "\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9759a947-111c-49c5-a8ea-c34b8aa57fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the pre-trained BERT to our define architecture\n",
    "model = BERT_Arch(bert)\n",
    "\n",
    "# push the model to GPU\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5a666e64-3226-46c8-98e4-ffd29569a2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "# define the optimizer\n",
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "58910ce2-3611-4bad-b742-c2265fd8de6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93428571 1.07565789]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Compute the class weights\n",
    "class_wts = compute_class_weight(class_weight='balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "\n",
    "print(class_wts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0e54c1fd-8d0c-4534-9e6d-d7f39fdf8b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class weights to tensor\n",
    "weights= torch.tensor(class_wts,dtype=torch.float)\n",
    "weights = weights.to(device)\n",
    "\n",
    "# loss function\n",
    "cross_entropy  = nn.NLLLoss(weight=weights) \n",
    "\n",
    "# number of training epochs\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364cc72c-706b-4915-ad2f-972356e1f303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "45efee50-4ad7-436e-80df-9898cf687d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate():\n",
    "  \n",
    "  print(\"\\nEvaluating...\")\n",
    "  \n",
    "  # deactivate dropout layers\n",
    "  model.eval()\n",
    "\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "  # empty list to save the model predictions\n",
    "  total_preds = []\n",
    "\n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(val_dataloader):\n",
    "    \n",
    "    # Progress update every 50 batches.\n",
    "    if step % 50 == 0 and not step == 0:\n",
    "      \n",
    "      # Calculate elapsed time in minutes.\n",
    "      elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "      # Report progress.\n",
    "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
    "\n",
    "    # push the batch to gpu\n",
    "    batch = [t.to(device) for t in batch]\n",
    "\n",
    "    sent_id, mask, labels = batch\n",
    "\n",
    "    # deactivate autograd\n",
    "    with torch.no_grad():\n",
    "      \n",
    "      # model predictions\n",
    "      preds = model(sent_id, mask)\n",
    "\n",
    "      # compute the validation loss between actual and predicted values\n",
    "      loss = cross_entropy(preds,labels)\n",
    "\n",
    "      total_loss = total_loss + loss.item()\n",
    "\n",
    "      preds = preds.detach().cpu().numpy()\n",
    "\n",
    "      total_preds.append(preds)\n",
    "\n",
    "  # compute the validation loss of the epoch\n",
    "  avg_loss = total_loss / len(val_dataloader) \n",
    "\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "  return avg_loss, total_preds\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9171582f-09f6-4ce5-b2d4-e200daaace48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent_id type: <class 'torch.Tensor'>\n",
      "mask type: <class 'torch.Tensor'>\n",
      "sent_id shape: torch.Size([327, 25])\n",
      "mask shape: torch.Size([327, 25])\n"
     ]
    }
   ],
   "source": [
    "# Create sent_id and mask tensors\n",
    "sent_id = torch.LongTensor(tokens_train['input_ids']).to(device)\n",
    "mask = torch.FloatTensor(tokens_train['attention_mask']).to(device)\n",
    "\n",
    "print(f\"sent_id type: {type(sent_id)}\")\n",
    "print(f\"mask type: {type(mask)}\")\n",
    "\n",
    "print(f\"sent_id shape: {sent_id.shape}\")\n",
    "print(f\"mask shape: {mask.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "00d91680-c43a-4ee1-8fd7-bfde4addf3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 10\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "train() takes 0 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Epoch \u001b[39m\u001b[38;5;132;01m{:}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{:}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, epochs))\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# train model\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m train_loss, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43msent_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# evaluate model\u001b[39;00m\n\u001b[0;32m     23\u001b[0m valid_loss, _ \u001b[38;5;241m=\u001b[39m evaluate()\n",
      "\u001b[1;31mTypeError\u001b[0m: train() takes 0 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create sent_id and mask tensors\n",
    "sent_id = torch.LongTensor(tokens_train['input_ids']).to(device)\n",
    "mask = torch.FloatTensor(tokens_train['attention_mask']).to(device)\n",
    "\n",
    "# Create labels tensor for the training set\n",
    "train_labels = torch.LongTensor(train_labels.tolist()).to(device)\n",
    "\n",
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "# for each epoch\n",
    "for epoch in range(epochs):\n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "\n",
    "    # train model\n",
    "    train_loss, _ = train(sent_id, mask, train_labels)\n",
    "\n",
    "    # evaluate model\n",
    "    valid_loss, _ = evaluate()\n",
    "\n",
    "    # save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "\n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8758e9-c137-454b-a178-1789a987564f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63723307-2e10-49e5-a35a-64858f46c0f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
